{
  "dataset_reader": {
    "type": "propbank_srl_span_reader",
    "max_span_width": 13,
    "token_indexers": {
      "tokens": {
        "type": "single_id",
        "lowercase_tokens": true
      },
      "elmo": {
        "type": "elmo_characters"
      }
    }
  },
  "train_data_path": "/home/swabhas/data/conll-formatted-ontonotes-5.0-12/conll-formatted-ontonotes-5.0/data/train/",
  "validation_data_path": "/home/swabhas/data/conll-formatted-ontonotes-5.0-12/conll-formatted-ontonotes-5.0/data/development/",
  "test_data_path": "/home/swabhas/data/conll-formatted-ontonotes-5.0-12/conll-formatted-ontonotes-5.0/data/test/",
  "model": {
    "type": "propbank_semi_crf_srl",
    "text_field_embedder": {
      "tokens": {
        "type": "embedding",
        "embedding_dim": 100,
        "pretrained_file": "/home/swabhas/data/glove.6B.100d.zip",
        "trainable": true
      },
      "elmo":{
        "type": "elmo_token_embedder",
        "options_file": "/home/swabhas/data/elmo/elmo_2x4096_512_2048cnn_2xhighway_options.json",
        "weight_file": "/home/swabhas/data/elmo/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5",
        "do_layer_norm": false,
        "dropout": 0.1
      }
    },
    "initializer": [
      [".*_projection_layer.*weight", {"type": "orthogonal"}]
    ],
    "encoder": {
      "type": "alternating_lstm",
      "input_size": 1224,
      "hidden_size": 300,
      "num_layers": 6,
      "recurrent_dropout_probability": 0.1,
      "use_input_projection_bias": false
    },
    "span_feedforward": {
      "input_dim": 909,
      "num_layers": 2,
      "hidden_dims": 150,
      "activations": "relu",
      "dropout": 0.2
    },
    "binary_feature_dim": 100,
    "max_span_width": 13,
    "binary_feature_size": 2,
    "loss_type": "hamming",
    "regularizer": [
      [
          ".*scalar_parameters.*",
          {
              "type": "l2",
              "alpha": 0.001
          }
      ]
  ]
  },
  "iterator": {
    "type": "bucket",
    "sorting_keys": [
      [
        "tokens",
        "num_tokens"
      ]
    ],
    "batch_size": 64
  },
  "trainer": {
    "num_epochs": 100,
    "grad_clipping": 1.0,
    "patience": 20,
    "num_serialized_models_to_keep": 3,
    "validation_metric": "+f1-measure-overall",
    "cuda_device": 0,
    "optimizer": {
      "type": "adam",
      "lr": 0.001
    }
  }
}